{
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "ca6bda83-afc4-4845-9b0f-834adfbe7b95",
        "responseMode": "responseNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -4800,
        672
      ],
      "id": "98700041-8345-4f05-bd55-90ee9206e18d",
      "name": "YouTube Download Webhook",
      "webhookId": "ca6bda83-afc4-4845-9b0f-834adfbe7b95"
    },
    {
      "parameters": {
        "jsCode": "// Validate input parameters\nconst item = $input.first();\nconst body = item.json.body || item.json;\n\n// YouTube URL\nconst youtubeUrl = body.youtube_url || body.url;\nif (!youtubeUrl) {\n  throw new Error('Missing required parameter: youtube_url');\n}\n\nif (!youtubeUrl.includes('youtube.com') && !youtubeUrl.includes('youtu.be')) {\n  throw new Error('Invalid YouTube URL');\n}\n\n// Optional segment times (if not provided, downloads full video)\nconst segmentStart = body.segment_start || null;\nconst segmentEnd = body.segment_end || null;\n\nif (segmentStart !== null && segmentEnd !== null && segmentEnd <= segmentStart) {\n  throw new Error('segment_end must be greater than segment_start');\n}\n\nreturn [{\n  json: {\n    youtube_url: youtubeUrl,\n    segment_start: segmentStart,\n    segment_end: segmentEnd,\n    format: 'mp3'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4608,
        672
      ],
      "id": "0a5e6525-326e-4880-a842-deacf382aa7b",
      "name": "Validate Input"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://yttools:8456/api/download",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({\n  \"url\": $json.youtube_url,\n  \"start_time\": $json.segment_start,\n  \"end_time\": $json.segment_end,\n  \"download_type\": \"both\",\n  \"audio_format\": \"wav\",\n  \"video_format\": \"mp4\",\n  \"enable_whisper\": true,\n  \"include_youtube_transcript\": false\n}) }}",
        "options": {
          "timeout": 60000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -4400,
        672
      ],
      "id": "6f5f3a9d-3fe5-41b0-a5f8-c7f1307689c6",
      "name": "Submit to yttools"
    },
    {
      "parameters": {
        "jsCode": "// Extract task_id from yttools response\nconst item = $input.first();\nconst response = item.json;\n\nif (!response.task_id) {\n  throw new Error('yttools did not return task_id: ' + JSON.stringify(response));\n}\n\nreturn [{\n  json: {\n    task_id: response.task_id,\n    youtube_url: $('Validate Input').item.json.youtube_url,\n    segment_start: $('Validate Input').item.json.segment_start,\n    segment_end: $('Validate Input').item.json.segment_end,\n    poll_count: 0,\n    max_polls: 120\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4192,
        672
      ],
      "id": "f21e6630-871d-440b-883a-e5a578bebcf2",
      "name": "Extract Task ID"
    },
    {
      "parameters": {
        "amount": 3
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -4784,
        912
      ],
      "id": "c630a383-d579-43e3-bd66-ebfb415c6eab",
      "name": "Wait 3s",
      "webhookId": "1b598c88-392d-4286-a898-ead60fde558d"
    },
    {
      "parameters": {
        "url": "=http://yttools:8456/api/status/{{ $json.task_id }}",
        "options": {
          "timeout": 10000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -4592,
        912
      ],
      "id": "95797d53-0503-4796-922f-bb820bd5e957",
      "name": "Check Status"
    },
    {
      "parameters": {
        "jsCode": "// Check if task is complete\nconst item = $input.first();\nconst status = item.json;\n\nconst taskId = $('Extract Task ID').item.json.task_id;\nconst pollCount = ($('Extract Task ID').item.json.poll_count || 0) + 1;\nconst maxPolls = $('Extract Task ID').item.json.max_polls || 120;\n\nif (pollCount >= maxPolls) {\n  throw new Error(`Task timeout after ${maxPolls} attempts`);\n}\n\nif (status.status === 'completed') {\n  return [{\n    json: {\n      task_id: taskId,\n      status: 'completed',\n      ready_to_download: true,\n      youtube_url: $('Validate Input').item.json.youtube_url,\n      segment_start: $('Validate Input').item.json.segment_start,\n      segment_end: $('Validate Input').item.json.segment_end,\n      result: status.result || {}\n    }\n  }];\n} else if (status.status === 'failed') {\n  throw new Error(`yttools task failed: ${status.error || 'Unknown error'}`);\n} else {\n  return [{\n    json: {\n      task_id: taskId,\n      status: status.status,\n      progress: status.progress || 0,\n      poll_count: pollCount,\n      max_polls: maxPolls,\n      ready_to_download: false\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4384,
        912
      ],
      "id": "a7fd01ad-4dda-485e-b234-b4bf5ab4facb",
      "name": "Check Completion"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "is-complete",
              "leftValue": "={{ $json.status }}",
              "rightValue": "completed",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -4192,
        912
      ],
      "id": "69227832-80cc-4606-90d8-60301034e055",
      "name": "Is Complete?"
    },
    {
      "parameters": {
        "url": "=http://yttools:8456/api/download/{{ $json.task_id }}/audio",
        "options": {
          "response": {
            "response": {
              "responseFormat": "file"
            }
          },
          "timeout": 30000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3648,
        1440
      ],
      "id": "7a962352-f168-4223-ab70-581a03fdf266",
      "name": "Download Audio"
    },
    {
      "parameters": {
        "url": "=http://yttools:8456/api/download/{{ $json.task_id }}/video",
        "options": {
          "response": {
            "response": {
              "responseFormat": "file"
            }
          },
          "timeout": 30000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3648,
        1248
      ],
      "id": "3cd641b4-1ccf-4e88-a130-1e6e25f85629",
      "name": "Download Video"
    },
    {
      "parameters": {
        "operation": "text",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -3648,
        896
      ],
      "id": "21555c2d-d934-4f42-893f-3da3af72e6fe",
      "name": "Extract SRT Content"
    },
    {
      "parameters": {
        "jsonSchema": "={\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"clips\": {\n      \"type\": \"array\",\n      \"description\": \"Array of 5-7 identified clip segments\",\n      \"minItems\": 5,\n      \"maxItems\": 7,\n      \"items\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"clip_number\": {\n            \"type\": \"integer\",\n            \"description\": \"Sequential clip number (1-7)\"\n          },\n          \"title_hook\": {\n            \"type\": \"string\",\n            \"description\": \"Suggested title hook for the Short (concise, engaging)\"\n          },\n          \"clip_type\": {\n            \"type\": \"string\",\n            \"enum\": [\"Aha! Moment\", \"Validating Statement\", \"Relatable Question\", \"Perspective Shift\"],\n            \"description\": \"Type of clip identified\"\n          },\n          \"timestamp_start\": {\n            \"type\": \"string\",\n            \"pattern\": \"^\\\\d{2}:\\\\d{2}:\\\\d{2},\\\\d{3}$\",\n            \"description\": \"Start timestamp in SRT format (HH:MM:SS,mmm)\"\n          },\n          \"timestamp_end\": {\n            \"type\": \"string\",\n            \"pattern\": \"^\\\\d{2}:\\\\d{2}:\\\\d{2},\\\\d{3}$\",\n            \"description\": \"End timestamp in SRT format (HH:MM:SS,mmm)\"\n          },\n          \"full_text\": {\n            \"type\": \"string\",\n            \"description\": \"Complete word-for-word transcript of the clip\"\n          },\n          \"directors_note\": {\n            \"type\": \"string\",\n            \"description\": \"Brief explanation of why this clip is powerful\"\n          }\n        },\n        \"required\": [\n          \"clip_number\",\n          \"title_hook\",\n          \"clip_type\",\n          \"timestamp_start\",\n          \"timestamp_end\",\n          \"full_text\",\n          \"directors_note\"\n        ]\n      }\n    },\n    \"analysis_summary\": {\n      \"type\": \"string\",\n      \"description\": \"Brief summary of the overall video content\"\n    }\n  },\n  \"required\": [\"clips\"]\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1,
      "position": [
        -3280,
        1072
      ],
      "id": "43735f8c-3663-4523-a127-738e52682ebc",
      "name": "Stage 1: Output Parser"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ \"**You are:** A specialist Short-Form Video Producer and Content Strategist for mental health and trauma recovery content.\\n\\n**Your Goal:** Analyze this SRT subtitle file and identify the **Top 5-7 most powerful clips** (15-60 seconds each) that can become high-impact YouTube Shorts.\\n\\n**The Channel:** Created by Peggy Oliveira, MSW, for survivors of childhood trauma. Brand tone: Compassionate, Validating, Authoritative, Healing-Focused.\\n\\n**What to Look For:**\\n\\n1. **Aha! Moments:** Clear definitions of psychological terms (emotional flashback, fawning, inner child) or perspective shifts (\\\"You're not broken, you are...\\\")\\n2. **Validating Statements:** Direct empathy (\\\"It was not your fault\\\")\\n3. **Relatable Questions:** Clips starting with powerful hooks (\\\"Do you ever find yourself...?\\\")\\n4. **Perspective Shifts:** Reframing negative beliefs\\n5. **Duration:** 15-60 seconds when spoken\\n6. **Self-Contained:** Must make complete sense on its own\\n\\n**Avoid:**\\n- Academic content without emotional payoff\\n- Dependent on prior context\\n- Listicle format (\\\"The third thing is...\\\")\\n\\n**SRT Content:**\\n\\n\" + $json.data }}",
        "hasOutputParser": true,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        -3472,
        896
      ],
      "id": "53677ae0-b0d4-466d-9915-8c20964eaade",
      "name": "Stage 1: Clip Identification"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "clips-found",
              "leftValue": "={{ $json.clips.length }}",
              "rightValue": 0,
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -3184,
        896
      ],
      "id": "443c036a-4e49-45cc-9004-43ccf93e1518",
      "name": "Check If Clips Found"
    },
    {
      "parameters": {
        "jsCode": "// Parse structured JSON output from Stage 1 AI Agent\n// With Structured Output Parser, data comes directly in top-level fields (not wrapped in 'output')\nconst inputData = $input.first().json;\n\n// Check if we have clips directly (from Structured Output Parser)\nif (!inputData.clips) {\n  throw new Error('No clips field in AI Agent response. Available fields: ' + JSON.stringify(Object.keys(inputData)));\n}\n\nconst parsedOutput = inputData; // Data is already structured\n\n// Function to convert SRT timestamp to seconds\nfunction srtToSeconds(timestamp) {\n  const [time, ms] = timestamp.split(',');\n  const [hours, minutes, seconds] = time.split(':').map(Number);\n  return hours * 3600 + minutes * 60 + seconds + (parseInt(ms) / 1000);\n}\n\n// Function to convert seconds to SRT timestamp\nfunction secondsToSRT(seconds) {\n  const hours = Math.floor(seconds / 3600);\n  const minutes = Math.floor((seconds % 3600) / 60);\n  const secs = Math.floor(seconds % 60);\n  const ms = Math.round((seconds % 1) * 1000);\n  return `${String(hours).padStart(2, '0')}:${String(minutes).padStart(2, '0')}:${String(secs).padStart(2, '0')},${String(ms).padStart(3, '0')}`;\n}\n\n// Function to sanitize title for filename\nfunction sanitizeTitle(title) {\n  return title.toLowerCase().replace(/[^a-z0-9]+/g, '_').replace(/^_+|_+$/g, '');\n}\n\n// Extract power words from text (simple heuristic: words in caps, emotional words)\nfunction extractPowerWords(text, title) {\n  const emotionalWords = ['trauma', 'guilt', 'shame', 'healing', 'broken', 'safe', 'worthy', 'valid', 'fault'];\n  const words = text.toLowerCase().split(/\\s+/);\n  const found = words.filter(w => emotionalWords.includes(w)).slice(0, 2);\n  \n  // Add title words if we don't have enough\n  if (found.length < 2) {\n    const titleWords = title.split(/\\s+/).filter(w => w.length > 4).slice(0, 3 - found.length);\n    found.push(...titleWords);\n  }\n  \n  return found.length > 0 ? found : ['healing', 'trauma'];\n}\n\n// Convert from schema format to internal format with synthetic text_styling\nconst clips = parsedOutput.clips.map(clip => {\n  const startSeconds = srtToSeconds(clip.timestamp_start);\n  const endSeconds = srtToSeconds(clip.timestamp_end);\n  const duration = parseFloat((endSeconds - startSeconds).toFixed(3));\n  \n  // Generate synthetic text_styling (will be enhanced by Stage 2 later if needed)\n  const ctaStartSeconds = Math.max(startSeconds, endSeconds - 8); // Last 8 seconds\n  const hookTitle = clip.title_hook.replace(/\\s+/g, '\\n').substring(0, 60); // Break into lines\n  \n  return {\n    index: clip.clip_number,\n    title: clip.title_hook,\n    title_sanitized: sanitizeTitle(clip.title_hook),\n    type: clip.clip_type,\n    type_sanitized: sanitizeTitle(clip.clip_type),\n    start_timestamp: clip.timestamp_start,\n    end_timestamp: clip.timestamp_end,\n    start_seconds: startSeconds,\n    end_seconds: endSeconds,\n    duration: duration,\n    text: clip.full_text,\n    notes: clip.directors_note,\n    text_styling: {\n      hook_title_overlay: hookTitle,\n      power_words: extractPowerWords(clip.full_text, clip.title_hook),\n      cta_start_timestamp: secondsToSRT(ctaStartSeconds),\n      cta_promise_text: 'Watch the full video:',\n      cta_verbal_cue: ''\n    }\n  };\n});\n\nif (clips.length === 0) {\n  throw new Error('No clips found in AI output.');\n}\n\nreturn [{\n  json: {\n    clips: clips,\n    total_clips: clips.length,\n    ai_output: JSON.stringify(parsedOutput),\n    task_id: $('Extract Task ID').item.json.task_id,\n    youtube_url: $('Validate Input').item.json.youtube_url\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2928,
        880
      ],
      "id": "b92eb390-7ba7-4311-8e25-e95036290498",
      "name": "Parse AI Clips"
    },
    {
      "parameters": {
        "fileName": "=/tmp/video_{{ $('Extract Task ID').item.json.task_id }}.mp4",
        "options": {}
      },
      "type": "n8n-nodes-base.writeBinaryFile",
      "typeVersion": 1,
      "position": [
        -3040,
        1168
      ],
      "id": "ed0e97b1-e970-40d1-817b-a4529fe34a39",
      "name": "Write Video to Temp"
    },
    {
      "parameters": {
        "fileName": "=/tmp/video_{{ $('Extract Task ID').item.json.task_id }}.srt",
        "options": {}
      },
      "type": "n8n-nodes-base.writeBinaryFile",
      "typeVersion": 1,
      "position": [
        -3184,
        720
      ],
      "id": "fbe79e51-572f-44e5-aebe-f5bbfb5f70fa",
      "name": "Write SRT to Temp"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "numberInputs": 4,
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        -2640,
        832
      ],
      "id": "1683c7f2-339c-4d0e-b76f-7e4bfec4c5eb",
      "name": "Merge Temp File Results"
    },
    {
      "parameters": {
        "jsCode": "// Format no-clips-found response\nconst aiOutput = $input.first().json.output;\n\nreturn [{\n  json: {\n    status: 'no_clips_found',\n    clips_found: false,\n    analysis: aiOutput,\n    message: 'No suitable high-impact clips found in this video. The AI analysis explains why.',\n    suggestion: 'Try a different video with more educational/teaching content about trauma recovery concepts.'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2784,
        1168
      ],
      "id": "a579d491-1f08-461a-a490-e8eae57a1f90",
      "name": "Format No Clips Response"
    },
    {
      "parameters": {
        "respondWith": "allIncomingItems",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        -2160,
        1424
      ],
      "id": "5e156394-8ca2-45a6-9365-3442beeaa9e5",
      "name": "Respond to Webhook1"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-5-20250929",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4.5"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        -3504,
        1072
      ],
      "id": "c1390eff-314b-4a08-b90e-7e8130f24516",
      "name": "Anthropic Chat Model",
      "credentials": {
        "anthropicApi": {
          "id": "9ITdZP15p3HH1JkB",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "fileName": "=/tmp/whisperx_{{ $('Extract Task ID').item.json.task_id }}.json",
        "options": {}
      },
      "type": "n8n-nodes-base.writeBinaryFile",
      "typeVersion": 1,
      "position": [
        -3184,
        528
      ],
      "id": "2aad7765-d557-4c5d-b1d2-472a07059b9e",
      "name": "Write WhisperX JSON to Temp"
    },
    {
      "parameters": {
        "jsCode": "const whisperxData = JSON.parse($input.first().json.data);\nconst taskId = $('Extract Task ID').item.json.task_id;\n\n// Convert JSON to binary for file writing\nconst jsonString = JSON.stringify(whisperxData, null, 2);\nconst buffer = Buffer.from(jsonString, 'utf-8');\n\nreturn [{ \n  json: { \n    task_id: taskId \n  },\n  binary: {\n    data: {\n      data: buffer.toString('base64'),\n      mimeType: 'application/json',\n      fileName: `whisperx_${taskId}.json`\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3392,
        528
      ],
      "id": "3c0ccd80-c6df-4ef2-9a2e-34629cc4d549",
      "name": "Parse WhisperX JSON"
    },
    {
      "parameters": {
        "operation": "text",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -3648,
        528
      ],
      "id": "9df67afe-038a-4fd5-91f1-b7fdd396415c",
      "name": "Extract WhisperX JSON Content"
    },
    {
      "parameters": {
        "url": "=http://yttools:8456/api/download/{{ $json.task_id }}/transcript_json",
        "options": {
          "response": {
            "response": {
              "responseFormat": "file"
            }
          },
          "timeout": 30000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3856,
        528
      ],
      "id": "c678e715-bbd4-4f8b-8dd5-a653e9e90aca",
      "name": "Download WhisperX JSON"
    },
    {
      "parameters": {
        "url": "=http://yttools:8456/api/download/{{ $json.task_id }}/segment_srt",
        "options": {
          "response": {
            "response": {
              "responseFormat": "file"
            }
          },
          "timeout": 30000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -3856,
        720
      ],
      "id": "3c6a612e-425f-4d7e-9840-68a1cd085076",
      "name": "Download Segment SRT"
    },
    {
      "parameters": {
        "jsCode": "// Extract clips data from merged inputs\n// Input 0: Write Video to Temp\n// Input 1: Write SRT to Temp  \n// Input 2: Parse AI Clips (has the actual data we need)\n// Input 3: Write WhisperX JSON to Temp\n\nconst inputs = $input.all();\n\n// Find the input that has clips data (from Parse AI Clips)\nlet parseClipsData = null;\nfor (const input of inputs) {\n  if (input.json.clips) {\n    parseClipsData = input.json;\n    break;\n  }\n}\n\nif (!parseClipsData || !parseClipsData.clips) {\n  throw new Error('Parse AI Clips data not found in merge inputs');\n}\n\nreturn [{\n  json: {\n    clips: parseClipsData.clips,\n    total_clips: parseClipsData.total_clips,\n    task_id: parseClipsData.task_id,\n    youtube_url: parseClipsData.youtube_url,\n    ai_output: parseClipsData.ai_output\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2432,
        864
      ],
      "id": "95a5a141-0201-4c38-8d91-699b57a8625d",
      "name": "Extract Clips Data"
    },
    {
      "parameters": {
        "jsCode": "// Combine clip data with temp file paths\n// After merge, data from all three inputs is combined\nconst inputData = $input.first().json;\n\n// Get clips data (should come from Parse AI Clips input)\nconst clips = inputData.clips;\nconst taskId = inputData.task_id;\nconst youtubeUrl = inputData.youtube_url;\n\nif (!clips) {\n  throw new Error('clips field not found in merged data. Input structure: ' + JSON.stringify(Object.keys(inputData)));\n}\n\nconst videoPath = `/tmp/video_${taskId}.mp4`;\nconst srtPath = `/tmp/video_${taskId}.srt`;\n\nreturn [{\n  json: {\n    clips: clips,\n    total_clips: clips.length,\n    task_id: taskId,\n    youtube_url: youtubeUrl,\n    video_path: videoPath,\n    srt_path: srtPath\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2160,
        464
      ],
      "id": "272d9591-ab07-4017-8409-f7e0f4553a4b",
      "name": "Add Temp Paths to Data"
    },
    {
      "parameters": {
        "jsCode": "// Wait for directory creation, then pass through original data\nconst originalData = $('Add Temp Paths to Data').item.json;\nreturn [{ json: originalData }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1536,
        464
      ],
      "id": "571ae0c8-b789-4dd0-b460-d33c7ed8a0a5",
      "name": "Wait for Directory Creation"
    },
    {
      "parameters": {
        "fieldToSplitOut": "clips",
        "include": "allOtherFields",
        "options": {}
      },
      "type": "n8n-nodes-base.splitOut",
      "typeVersion": 1,
      "position": [
        -2160,
        688
      ],
      "id": "ef68c9fb-5186-46a9-a49a-8e1d33d2eeb1",
      "name": "Split Out Clips"
    },
    {
      "parameters": {
        "command": "mkdir -p /nas/PeggysExtraStorage/videos-to-process/processed/shorts"
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        -1952,
        464
      ],
      "id": "e4fbfca9-d7df-488a-a85a-d340f300dad0",
      "name": "Create Output Directory"
    },
    {
      "parameters": {
        "command": "mkdir -p /nas/PeggysExtraStorage/videos-to-process/scratch"
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        -1744,
        464
      ],
      "id": "f513d965-9aa2-489f-a194-d812e3996604",
      "name": "Create Scratch Directory"
    },
    {
      "parameters": {
        "jsCode": "// Build ffmpeg command for extracting and enhancing clip\n// Get the original clip data from 'Split Out Clips' node (before Execute Command)\nconst splitOutData = $('Split Out Clips').item.json;\nconst data = splitOutData;\nconst clip = data.clips || data; // Handle both nested and flat structures\nconst videoPath = data.video_path;\nconst taskId = data.task_id;\nconst aiOutput = data.ai_output; // Pass through AI output\n\n// Get video title from YouTube URL or use task ID\nconst youtubeUrl = data.youtube_url || '';\nconst videoId = youtubeUrl.match(/(?:v=|youtu\\.be\\/)([^&\\?]+)/)?.[1] || taskId;\nconst baseFilename = `${videoId}_clip_${String(clip.index).padStart(2, '0')}_${clip.type_sanitized}`;\n\nconst outputPath = `/nas/PeggysExtraStorage/videos-to-process/processed/shorts/${baseFilename}.mp4`;\nconst assPath = `/tmp/subtitle_${taskId}_clip_${String(clip.index).padStart(2, '0')}.ass`;\n\n// Build ffmpeg command with:\n// 1. Extract segment (-ss start, -to end)\n// 2. Crop to 9:16 vertical format\n// 3. Burn-in ASS subtitles with custom styling and text overlays\n// 4. Encode with H.264 + AAC\n// Build ffmpeg command for extracting clip WITHOUT subtitles\n// Subtitles will be added in a later step after WhisperX transcription\nconst outputPathNoSubs = `/nas/PeggysExtraStorage/videos-to-process/scratch/${baseFilename}_nosubs.mp4`;\n\nconst ffmpegCmd = `ffmpeg -y -i \\\"${videoPath}\\\" \\\\\n    -ss ${clip.start_seconds} \\\\\n    -to ${clip.end_seconds} \\\\\n    -vf \\\"crop=ih*9/16:ih\\\" \\\\\n    -c:v libx264 -crf 23 -preset fast \\\\\n    -c:a aac -b:a 128k \\\\\n    -movflags +faststart \\\\\n    \\\"${outputPathNoSubs}\\\"`;\n\nreturn [{\n  json: {\n    ...data,\n    clip: clip,\n    ffmpeg_command: ffmpegCmd,\n    output_path_nosubs: outputPathNoSubs,\n    output_path_final: outputPath,\n    base_filename: baseFilename,\n    ass_path: assPath,\n    ai_output: aiOutput\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1952,
        688
      ],
      "id": "c72a5c8c-cfd9-4166-b063-642f2915a8b7",
      "name": "Prepare ffmpeg Command"
    },
    {
      "parameters": {
        "command": "={{ $json.ffmpeg_command }}"
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        -1744,
        688
      ],
      "id": "72a5a762-b12b-43e0-94ea-e314563a31e3",
      "name": "Extract Video Clip"
    },
    {
      "parameters": {
        "filePath": "={{ $('Prepare ffmpeg Command').item.json.output_path_nosubs }}"
      },
      "type": "n8n-nodes-base.readBinaryFile",
      "typeVersion": 1,
      "position": [
        -1536,
        688
      ],
      "id": "4ce1645d-f486-4495-b4dd-80f8ff249aee",
      "name": "Read Clip Video File"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://whisperx:8000/transcribe",
        "sendBody": true,
        "contentType": "multipart-form-data",
        "bodyParameters": {
          "parameters": [
            {
              "parameterType": "formBinaryData",
              "name": "file",
              "inputDataFieldName": "data"
            },
            {
              "name": "model",
              "value": "base"
            },
            {
              "name": "enable_diarization",
              "value": "false"
            }
          ]
        },
        "options": {
          "allowUnauthorizedCerts": true,
          "timeout": 120000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2160,
        912
      ],
      "id": "8e51c4f0-30bd-4e6c-8bbf-c17a68b25f2d",
      "name": "Transcribe Short Video with WhisperX"
    },
    {
      "parameters": {
        "jsCode": "// Extract WhisperX transcription for this entire short video clip\n// Timestamps now start at 0:00:00 for the clip (not original video time)\nconst whisperxResult = $input.first().json;\nconst prepareData = $('Prepare ffmpeg Command').item.json;\n\n// Verify we got segments back\nif (!whisperxResult.segments || whisperxResult.segments.length === 0) {\n  throw new Error(`WhisperX returned no segments for clip ${prepareData.clip.index}`);\n}\n\nconsole.log(`WhisperX transcribed ${whisperxResult.segments.length} segments for clip ${prepareData.clip.index}`);\nconsole.log(`Duration: ${prepareData.clip.duration}s, Language: ${whisperxResult.language}`);\n\n// Pass through clip data + add WhisperX results\nreturn [{\n  json: {\n    ...prepareData,\n    whisperx_segments: whisperxResult.segments,\n    whisperx_srt: whisperxResult.srt,\n    whisperx_segments_srt: whisperxResult.segments_srt,\n    whisperx_txt: whisperxResult.txt,\n    clip_language: whisperxResult.language,\n    num_segments: whisperxResult.segments.length\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1952,
        912
      ],
      "id": "8eb9a19b-8b1d-4fea-b991-10dec1219657",
      "name": "Parse WhisperX Clip Response"
    },
    {
      "parameters": {
        "jsCode": "// Generate sentence-aware ASS subtitles directly from WhisperX segments\nconst data = $input.first().json;\nconst clip = data.clip;\nconst taskId = data.task_id;\nconst segments = data.whisperx_segments;\n\n// ===== CONFIGURATION =====\nconst CONFIG = {\n  wordsToShow: 3,\n  fontName: 'Arial',\n  fontSize: 80,  // Reduced from 130\n  fontColor: 'FFFFFF',\n  outlineColor: '000000',\n  backgroundColor: '000000',\n  highlightFontSize: 100,  // Reduced from 150 (still 25% larger than base for zoom effect)\n  highlightColor: '00FFFF',\n  bold: 0,\n  italic: 0,\n  underline: 0,\n  strikeout: 0,\n  scaleX: 100,\n  scaleY: 100,\n  spacing: 0,\n  angle: 0,\n  borderStyle: 1,\n  outline: 8,  // Reduced from 10\n  shadow: 1,\n  alignment: 2,\n  marginL: 10,\n  marginR: 10,\n  marginV: 300,\n  videoWidth: 1080,  // 9:16 vertical format\n  videoHeight: 1920,\n  maxGapTimeMs: 2000,\n  // Hook title styling\n  hookTitleFontSize: 120,  // Reduced from 180\n  hookTitleColor: 'FFFF00',  // Yellow\n  hookTitleDuration: 2.0,  // Show for 2 seconds at start\n  hookTitleAlignment: 5,  // Center\n  hookTitleMarginV: 100,\n  // CTA styling\n  ctaFontSize: 90,  // Reduced from 140\n  ctaColor: 'FF00FF',  // Magenta\n  ctaDuration: 8.0,  // Show for last 8 seconds\n  ctaAlignment: 8,  // Top center\n  ctaMarginV: 100\n};\n\n// Helper: convert seconds to ASS time format (H:MM:SS.cs)\nfunction formatTime(sec) {\n  const h = Math.floor(sec / 3600);\n  const m = Math.floor((sec % 3600) / 60);\n  const s = Math.floor(sec % 60);\n  const cs = Math.floor((sec - Math.floor(sec)) * 100);\n  return `${h}:${m.toString().padStart(2, '0')}:${s.toString().padStart(2, '0')}.${cs.toString().padStart(2, '0')}`;\n}\n\n// Creates subtitle text with specified word highlighted\nfunction createSubtitleText(wordGroup, highlightIndex) {\n  let line = '';\n  wordGroup.forEach((word, i) => {\n    if (i > 0) line += ' ';\n    if (i === highlightIndex) {\n      line += `{\\\\fs${CONFIG.highlightFontSize}\\\\c&H${CONFIG.highlightColor}&}${word.word.trim()}{\\\\r}`;\n    } else {\n      line += word.word.trim();\n    }\n  });\n  return line;\n}\n\n// Process all segments to get all words\nlet allWords = [];\nsegments.forEach(segment => {\n  if (segment.words && segment.words.length > 0) {\n    allWords = allWords.concat(segment.words);\n  }\n});\n\n// Sort by start time\nallWords.sort((a, b) => a.start - b.start);\n\n// Create sentence-aware word groups\nfunction createSentenceAwareGroups(words) {\n  const groups = [];\n  let currentGroup = [];\n  \n  for (let i = 0; i < words.length; i++) {\n    const currentWord = words[i];\n    currentGroup.push(currentWord);\n    \n    const endsWithPeriod = currentWord.word.trim().endsWith('.');\n    \n    if (currentGroup.length >= CONFIG.wordsToShow || endsWithPeriod || i === words.length - 1) {\n      if (currentGroup.length > 0) {\n        groups.push([...currentGroup]);\n        currentGroup = [];\n      }\n    }\n  }\n  \n  if (currentGroup.length > 0) {\n    groups.push(currentGroup);\n  }\n  \n  return groups;\n}\n\nconst wordGroups = createSentenceAwareGroups(allWords);\nlet dialogueLines = [];\n\n// Generate dialogue lines for each word\nfor (let i = 0; i < allWords.length; i++) {\n  const currentWord = allWords[i];\n  \n  // Find which group contains this word\n  let groupIndex = -1;\n  let positionIndex = -1;\n  \n  for (let g = 0; g < wordGroups.length; g++) {\n    const wordIndex = wordGroups[g].findIndex(w => \n      w.start === currentWord.start && w.end === currentWord.end && w.word === currentWord.word);\n    \n    if (wordIndex !== -1) {\n      groupIndex = g;\n      positionIndex = wordIndex;\n      break;\n    }\n  }\n  \n  if (groupIndex === -1) continue;\n  \n  const wordGroup = wordGroups[groupIndex];\n  const startTime = currentWord.start;\n  const endTime = currentWord.end;\n  const formattedStart = formatTime(startTime);\n  const formattedEnd = formatTime(endTime);\n  const subtitleText = createSubtitleText(wordGroup, positionIndex);\n  \n  dialogueLines.push({\n    start: startTime,\n    end: endTime,\n    formattedStart,\n    formattedEnd,\n    text: subtitleText,\n    group: groupIndex,\n    position: positionIndex\n  });\n}\n\n// Fill gaps between dialogues in same group\nfor (let i = 0; i < dialogueLines.length - 1; i++) {\n  const current = dialogueLines[i];\n  const next = dialogueLines[i + 1];\n  \n  if (current.group === next.group && next.start - current.end > 0 && next.start - current.end <= CONFIG.maxGapTimeMs / 1000) {\n    current.end = next.start;\n    current.formattedEnd = formatTime(current.end);\n  }\n}\n\n// Build ASS file content with multiple styles\nlet ass = `[Script Info]\nTitle: Sentence-Aware Fixed Position Subtitles with Hook and CTA\nScriptType: v4.00+\nPlayResX: ${CONFIG.videoWidth}\nPlayResY: ${CONFIG.videoHeight}\n\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\nStyle: Default,${CONFIG.fontName},${CONFIG.fontSize},&H${CONFIG.fontColor},&H${CONFIG.outlineColor},&H${CONFIG.outlineColor},&H${CONFIG.backgroundColor},${CONFIG.bold},${CONFIG.italic},${CONFIG.underline},${CONFIG.strikeout},${CONFIG.scaleX},${CONFIG.scaleY},${CONFIG.spacing},${CONFIG.angle},${CONFIG.borderStyle},${CONFIG.outline},${CONFIG.shadow},${CONFIG.alignment},${CONFIG.marginL},${CONFIG.marginR},${CONFIG.marginV},1\nStyle: HookTitle,${CONFIG.fontName},${CONFIG.hookTitleFontSize},&H${CONFIG.hookTitleColor},&H${CONFIG.outlineColor},&H${CONFIG.outlineColor},&H${CONFIG.backgroundColor},1,${CONFIG.italic},${CONFIG.underline},${CONFIG.strikeout},${CONFIG.scaleX},${CONFIG.scaleY},${CONFIG.spacing},${CONFIG.angle},${CONFIG.borderStyle},${CONFIG.outline},${CONFIG.shadow},${CONFIG.hookTitleAlignment},${CONFIG.marginL},${CONFIG.marginR},${CONFIG.hookTitleMarginV},1\nStyle: CTA,${CONFIG.fontName},${CONFIG.ctaFontSize},&H${CONFIG.ctaColor},&H${CONFIG.outlineColor},&H${CONFIG.outlineColor},&H${CONFIG.backgroundColor},1,${CONFIG.italic},${CONFIG.underline},${CONFIG.strikeout},${CONFIG.scaleX},${CONFIG.scaleY},${CONFIG.spacing},${CONFIG.angle},${CONFIG.borderStyle},${CONFIG.outline},${CONFIG.shadow},${CONFIG.ctaAlignment},${CONFIG.marginL},${CONFIG.marginR},${CONFIG.ctaMarginV},1\n\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n`;\n\n// Add hook title at the beginning\nconst hookTitle = clip.text_styling?.hook_title_overlay || clip.title;\nconst hookEndTime = Math.min(CONFIG.hookTitleDuration, clip.duration);\nass += `Dialogue: 1,${formatTime(0)},${formatTime(hookEndTime)},HookTitle,,0,0,0,,${hookTitle.replace(/\\n/g, '\\\\N')}\\n`;\n\n// Add all word-by-word dialogue lines\ndialogueLines.forEach(line => {\n  ass += `Dialogue: 0,${line.formattedStart},${line.formattedEnd},Default,,0,0,0,,${line.text}\\n`;\n});\n\n// Add CTA at the end\nconst ctaText = clip.text_styling?.cta_promise_text || 'Watch the full video';\nconst ctaStartTime = Math.max(0, clip.duration - CONFIG.ctaDuration);\nass += `Dialogue: 2,${formatTime(ctaStartTime)},${formatTime(clip.duration)},CTA,,0,0,0,,${ctaText}\\n`;\n\nconst assPath = `/nas/PeggysExtraStorage/videos-to-process/scratch/subtitle_clip_${taskId}_${String(clip.index).padStart(2, '0')}.ass`;\n\nreturn [{\n  json: {\n    ...data,\n    ass_path: assPath,\n    subtitle_generated: true,\n    total_words: allWords.length,\n    total_groups: wordGroups.length,\n    total_dialogue_lines: dialogueLines.length\n  },\n  binary: {\n    data: {\n      data: Buffer.from(ass).toString('base64'),\n      mimeType: 'text/x-ssa',\n      fileName: `subtitle_clip_${taskId}_${String(clip.index).padStart(2, '0')}.ass`\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1744,
        912
      ],
      "id": "9f76c343-0101-44d7-b4ed-0b8c23763798",
      "name": "Generate Sentence-Aware ASS Subtitles"
    },
    {
      "parameters": {
        "fileName": "={{ $json.ass_path }}",
        "options": {}
      },
      "type": "n8n-nodes-base.writeBinaryFile",
      "typeVersion": 1,
      "position": [
        -1536,
        912
      ],
      "id": "2a9f332f-e9be-4aa3-bb37-353bec81a0eb",
      "name": "Write ASS File to Scratch"
    },
    {
      "parameters": {
        "jsCode": "// Apply ASS subtitles to the no-subs video\nconst data = $input.first().json;\n\nconst finalCmd = `ffmpeg -y -i \"${data.output_path_nosubs}\" \\\\\n    -vf \"ass='${data.ass_path}'\" \\\\\n    -c:v libx264 -crf 23 -preset fast \\\\\n    -c:a copy \\\\\n    -movflags +faststart \\\\\n    \"${data.output_path_final}\"`;\n\nreturn [{\n  json: {\n    ...data,\n    final_ffmpeg_command: finalCmd\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2160,
        1152
      ],
      "id": "a39f8788-a745-4d8b-a9e7-de0cd83586db",
      "name": "Build Final ffmpeg Command"
    },
    {
      "parameters": {
        "command": "={{ $json.final_ffmpeg_command }}"
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        -1952,
        1152
      ],
      "id": "be5e642e-eaa5-42d8-84a8-a72fbae52ea6",
      "name": "Apply Subtitles to Video"
    },
    {
      "parameters": {
        "jsCode": "// Verify clip was created by checking ffmpeg exit code\nconst execResult = $input.first().json;\nconst exitCode = execResult.exitCode;\n\n// Get clip data from Build Final ffmpeg Command node\nconst buildData = $('Build Final ffmpeg Command').item.json;\nconst clip = buildData.clip;\n\n// ffmpeg returns 0 on success\nif (exitCode === 0) {\n  return [{\n    json: {\n      clip_index: clip.index,\n      clip_title: clip.title,\n      output_path_nosubs: buildData.output_path_nosubs,\n      output_path_final: buildData.output_path_final,\n      duration: clip.duration,\n      status: 'success',\n      ai_output: buildData.ai_output\n    }\n  }];\n} else {\n  return [{\n    json: {\n      clip_index: clip.index,\n      clip_title: clip.title,\n      status: 'failed',\n      error: `ffmpeg failed with exit code ${exitCode}`,\n      stderr: execResult.stderr || 'No error output',\n      ai_output: buildData.ai_output\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1744,
        1152
      ],
      "id": "01957f75-fca0-4ff9-8aa6-2ac4aa8d94fb",
      "name": "Verify Clip Created"
    },
    {
      "parameters": {
        "jsCode": "// Aggregate all clip results\nconst allClips = $input.all();\nconst successful = allClips.filter(c => c.json.status === 'success');\nconst failed = allClips.filter(c => c.json.status === 'failed');\n\n// Get ai_output from first item (all items have the same ai_output)\nconst aiOutput = allClips[0]?.json.ai_output;\n\nreturn [{\n  json: {\n    total_clips: allClips.length,\n    successful_clips: successful.length,\n    failed_clips: failed.length,\n    clips: successful.map(c => ({\n      index: c.json.clip_index,\n      title: c.json.clip_title,\n      path_nosubs: c.json.output_path_nosubs,\n      path_final: c.json.output_path_final,\n      duration: c.json.duration\n    })),\n    errors: failed.map(c => ({\n      index: c.json.clip_index,\n      title: c.json.clip_title,\n      error: c.json.error\n    })),\n    ai_output: aiOutput\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1536,
        1152
      ],
      "id": "81c1d3ee-d3c1-4116-a435-8ec2a8231256",
      "name": "Aggregate Clip Results"
    },
    {
      "parameters": {
        "jsCode": "// Format successful clips response with extraction results\nconst clipResults = $input.first().json;\nconst aiOutput = clipResults.ai_output;\n\nreturn [{\n  json: {\n    status: 'success',\n    clips_found: true,\n    clips_extracted: clipResults.successful_clips,\n    total_clips_attempted: clipResults.total_clips,\n    analysis: aiOutput,\n    extracted_shorts: clipResults.clips,\n    storage_path_final: '/nas/PeggysExtraStorage/videos-to-process/processed/shorts',\n    storage_path_nosubs: '/nas/PeggysExtraStorage/videos-to-process/scratch',\n    message: `Successfully extracted ${clipResults.successful_clips} short video clips with sentence-aware subtitles (both versions saved)`,\n    errors: clipResults.errors\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1328,
        1152
      ],
      "id": "99e3bed4-c05b-471f-85c0-7e9bcb723f91",
      "name": "Format Success Response"
    }
  ],
  "connections": {
    "YouTube Download Webhook": {
      "main": [
        [
          {
            "node": "Validate Input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Input": {
      "main": [
        [
          {
            "node": "Submit to yttools",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Submit to yttools": {
      "main": [
        [
          {
            "node": "Extract Task ID",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Task ID": {
      "main": [
        [
          {
            "node": "Wait 3s",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait 3s": {
      "main": [
        [
          {
            "node": "Check Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Status": {
      "main": [
        [
          {
            "node": "Check Completion",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Completion": {
      "main": [
        [
          {
            "node": "Is Complete?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is Complete?": {
      "main": [
        [
          {
            "node": "Download Audio",
            "type": "main",
            "index": 0
          },
          {
            "node": "Download Video",
            "type": "main",
            "index": 0
          },
          {
            "node": "Download Segment SRT",
            "type": "main",
            "index": 0
          },
          {
            "node": "Download WhisperX JSON",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Wait 3s",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download Audio": {
      "main": [
        [
          {
            "node": "Respond to Webhook1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download Video": {
      "main": [
        [
          {
            "node": "Respond to Webhook1",
            "type": "main",
            "index": 0
          },
          {
            "node": "Write Video to Temp",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract SRT Content": {
      "main": [
        [
          {
            "node": "Stage 1: Clip Identification",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Stage 1: Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Stage 1: Clip Identification",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Stage 1: Clip Identification": {
      "main": [
        [
          {
            "node": "Check If Clips Found",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check If Clips Found": {
      "main": [
        [
          {
            "node": "Parse AI Clips",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Format No Clips Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse AI Clips": {
      "main": [
        [
          {
            "node": "Merge Temp File Results",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Write Video to Temp": {
      "main": [
        [
          {
            "node": "Merge Temp File Results",
            "type": "main",
            "index": 3
          }
        ]
      ]
    },
    "Write SRT to Temp": {
      "main": [
        [
          {
            "node": "Merge Temp File Results",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge Temp File Results": {
      "main": [
        [
          {
            "node": "Extract Clips Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format No Clips Response": {
      "main": [
        [
          {
            "node": "Respond to Webhook1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Stage 1: Clip Identification",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Write WhisperX JSON to Temp": {
      "main": [
        [
          {
            "node": "Merge Temp File Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse WhisperX JSON": {
      "main": [
        [
          {
            "node": "Write WhisperX JSON to Temp",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract WhisperX JSON Content": {
      "main": [
        [
          {
            "node": "Parse WhisperX JSON",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download WhisperX JSON": {
      "main": [
        [
          {
            "node": "Extract WhisperX JSON Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download Segment SRT": {
      "main": [
        [
          {
            "node": "Extract SRT Content",
            "type": "main",
            "index": 0
          },
          {
            "node": "Write SRT to Temp",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Clips Data": {
      "main": [
        [
          {
            "node": "Add Temp Paths to Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Add Temp Paths to Data": {
      "main": [
        [
          {
            "node": "Create Output Directory",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait for Directory Creation": {
      "main": [
        [
          {
            "node": "Split Out Clips",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Out Clips": {
      "main": [
        [
          {
            "node": "Prepare ffmpeg Command",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Output Directory": {
      "main": [
        [
          {
            "node": "Create Scratch Directory",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Scratch Directory": {
      "main": [
        [
          {
            "node": "Wait for Directory Creation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare ffmpeg Command": {
      "main": [
        [
          {
            "node": "Extract Video Clip",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Video Clip": {
      "main": [
        [
          {
            "node": "Read Clip Video File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Read Clip Video File": {
      "main": [
        [
          {
            "node": "Transcribe Short Video with WhisperX",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Transcribe Short Video with WhisperX": {
      "main": [
        [
          {
            "node": "Parse WhisperX Clip Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse WhisperX Clip Response": {
      "main": [
        [
          {
            "node": "Generate Sentence-Aware ASS Subtitles",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Sentence-Aware ASS Subtitles": {
      "main": [
        [
          {
            "node": "Write ASS File to Scratch",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Write ASS File to Scratch": {
      "main": [
        [
          {
            "node": "Build Final ffmpeg Command",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Final ffmpeg Command": {
      "main": [
        [
          {
            "node": "Apply Subtitles to Video",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Apply Subtitles to Video": {
      "main": [
        [
          {
            "node": "Verify Clip Created",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Verify Clip Created": {
      "main": [
        [
          {
            "node": "Aggregate Clip Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate Clip Results": {
      "main": [
        [
          {
            "node": "Format Success Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Success Response": {
      "main": [
        [
          {
            "node": "Respond to Webhook1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "meta": {
    "instanceId": "99ff97a0c56026a2c1b3a849547491eb857e68a0b770f2b7c6688eea83f57eda"
  }
}