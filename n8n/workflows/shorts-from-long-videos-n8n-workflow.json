{
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "shorts",
        "responseMode": "responseNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -592,
        784
      ],
      "id": "01821bf4-ee29-423b-968d-fd7dc014a5f2",
      "name": "YouTube Download Webhook",
      "webhookId": "shorts"
    },
    {
      "parameters": {
        "jsCode": "// Validate input parameters\nconst item = $input.first();\nconst body = item.json.body || item.json;\n\n// YouTube URL\nconst youtubeUrl = body.youtube_url || body.url;\nif (!youtubeUrl) {\n  throw new Error('Missing required parameter: youtube_url');\n}\n\nif (!youtubeUrl.includes('youtube.com') && !youtubeUrl.includes('youtu.be')) {\n  throw new Error('Invalid YouTube URL');\n}\n\n// Optional segment times (if not provided, downloads full video)\nconst segmentStart = body.segment_start || null;\nconst segmentEnd = body.segment_end || null;\n\nif (segmentStart !== null && segmentEnd !== null && segmentEnd <= segmentStart) {\n  throw new Error('segment_end must be greater than segment_start');\n}\n\nreturn [{\n  json: {\n    youtube_url: youtubeUrl,\n    segment_start: segmentStart,\n    segment_end: segmentEnd,\n    format: 'mp3'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -400,
        784
      ],
      "id": "35ccf173-599a-42fa-aa41-29d775721072",
      "name": "Validate Input"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://yttools:8456/api/download",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({\n  \"url\": $json.youtube_url,\n  \"start_time\": $json.segment_start,\n  \"end_time\": $json.segment_end,\n  \"download_type\": \"both\",\n  \"audio_format\": \"wav\",\n  \"video_format\": \"mp4\",\n  \"enable_whisper\": true,\n  \"include_youtube_transcript\": false\n}) }}",
        "options": {
          "timeout": 60000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -192,
        784
      ],
      "id": "8ec69f92-404b-4656-8a55-96935a8bfcea",
      "name": "Submit to yttools"
    },
    {
      "parameters": {
        "jsCode": "// Extract task_id from yttools response\nconst item = $input.first();\nconst response = item.json;\n\nif (!response.task_id) {\n  throw new Error('yttools did not return task_id: ' + JSON.stringify(response));\n}\n\nreturn [{\n  json: {\n    task_id: response.task_id,\n    youtube_url: $('Validate Input').item.json.youtube_url,\n    segment_start: $('Validate Input').item.json.segment_start,\n    segment_end: $('Validate Input').item.json.segment_end,\n    poll_count: 0,\n    max_polls: 120\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        16,
        784
      ],
      "id": "53991a9f-bd78-4931-a501-4833e13cc165",
      "name": "Extract Task ID"
    },
    {
      "parameters": {
        "jsCode": "// Format immediate response with task_id\nconst item = $input.first();\n\nreturn [{\n  json: {\n    status: 'processing',\n    task_id: item.json.task_id,\n    message: 'Processing started. Poll the status endpoint for updates.',\n    poll_url: `https://yttools.lan/api/status/${item.json.task_id}`\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        224,
        400
      ],
      "id": "57488a0c-3d09-4d17-ab21-b0e51161f3a0",
      "name": "Format Immediate Response"
    },
    {
      "parameters": {
        "jsCode": "// Get the clips data from Parse AI Clips\nconst data = $input.first().json;\n\n// Send progress update (async, don't wait)\nconst taskId = $('Extract Task ID').item.json.task_id;\nfetch(`http://yttools:8456/api/status/${taskId}/update`, {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    stage: 'extracting',\n    progress: 60,\n    message: 'Extracting clips...'\n  })\n}).catch(err => console.log('Progress update failed:', err));\n\n// Pass through original data\nreturn { json: data };"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1280,
        1008
      ],
      "id": "eb2ff874-469a-42dd-bfe4-a173b55087e0",
      "name": "Progress: Extracting Clips"
    },
    {
      "parameters": {
        "jsCode": "// Get the aggregate results data\nconst data = $input.first().json;\n\n// Send progress update (async, don't wait)\nconst taskId = $('Extract Task ID').item.json.task_id;\nfetch(`http://yttools:8456/api/status/${taskId}/update`, {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    stage: 'subtitling',\n    progress: 90,\n    message: 'Adding subtitles...'\n  })\n}).catch(err => console.log('Progress update failed:', err));\n\n// Pass through original data\nreturn { json: data };"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2864,
        1264
      ],
      "id": "699b3417-7b50-4ba8-82aa-7893408de788",
      "name": "Progress: Adding Subtitles"
    },
    {
      "parameters": {
        "jsCode": "// Get the success response data\nconst data = $input.first().json;\n\n// Send completion update (async, don't wait)\nconst taskId = $('Extract Task ID').item.json.task_id;\nfetch(`http://yttools:8456/api/status/${taskId}/update`, {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    stage: 'completed',\n    progress: 100,\n    message: 'Processing complete!',\n    clips_result: data\n  })\n}).catch(err => console.log('Progress update failed:', err));\n\n// Pass through original data\nreturn { json: data };"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2272,
        1504
      ],
      "id": "7cbb821e-bb54-42b5-bb92-854f76fa19e8",
      "name": "Progress: Completed"
    },
    {
      "parameters": {
        "amount": 3
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        -576,
        1024
      ],
      "id": "0aad5755-102c-4cad-a963-728957cb0ffd",
      "name": "Wait 3s",
      "webhookId": "1b598c88-392d-4286-a898-ead60fde558d"
    },
    {
      "parameters": {
        "url": "=http://yttools:8456/api/status/{{ $json.task_id }}",
        "options": {
          "timeout": 10000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -384,
        1024
      ],
      "id": "e3f62532-cf95-48bb-b36f-d23103cc78ad",
      "name": "Check Status"
    },
    {
      "parameters": {
        "jsCode": "// Check if task is complete\nconst item = $input.first();\nconst status = item.json;\n\nconst taskId = $('Extract Task ID').item.json.task_id;\nconst pollCount = (item.json.poll_count || 0) + 1;\nconst maxPolls = 2; // Loop limit\n\nif (pollCount > maxPolls) {\n  throw new Error(`Loop limit exceeded after ${pollCount} attempts`);\n}\n\nif (status.status === 'completed') {\n  return [{\n    json: {\n      task_id: taskId,\n      status: 'completed',\n      ready_to_download: true,\n      youtube_url: $('Validate Input').item.json.youtube_url,\n      segment_start: $('Validate Input').item.json.segment_start,\n      segment_end: $('Validate Input').item.json.segment_end,\n      result: status.result || {}\n    }\n  }];\n} else if (status.status === 'failed') {\n  throw new Error(`yttools task failed: ${status.error || 'Unknown error'}`);\n} else {\n  return [{\n    json: {\n      task_id: taskId,\n      status: status.status,\n      progress: status.progress || 0,\n      poll_count: pollCount,\n      max_polls: maxPolls,\n      ready_to_download: false\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -176,
        1024
      ],
      "id": "58f0d67f-931c-42ff-9567-7260ab39b26c",
      "name": "Check Completion"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "is-complete",
              "leftValue": "={{ $json.status }}",
              "rightValue": "completed",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        16,
        1024
      ],
      "id": "eeba9bda-5cc3-4186-bc68-6ff7d3071eb6",
      "name": "Is Complete?"
    },
    {
      "parameters": {
        "url": "=http://yttools:8456/api/download/{{ $json.task_id }}/audio",
        "options": {
          "response": {
            "response": {
              "responseFormat": "file"
            }
          },
          "timeout": 30000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        560,
        1552
      ],
      "id": "9c92e9b6-e5dc-48b8-a18c-1f6cd5445f92",
      "name": "Download Audio"
    },
    {
      "parameters": {
        "url": "=http://yttools:8456/api/download/{{ $json.task_id }}/video",
        "options": {
          "response": {
            "response": {
              "responseFormat": "file"
            }
          },
          "timeout": 30000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        560,
        1360
      ],
      "id": "7f81afcd-c46f-43f6-bb94-c435a610fb7f",
      "name": "Download Video"
    },
    {
      "parameters": {
        "operation": "text",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        448,
        976
      ],
      "id": "dbf48cc5-cf58-4421-a584-7a8ad3918024",
      "name": "Extract SRT Content"
    },
    {
      "parameters": {
        "jsonSchema": "={\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"clips\": {\n      \"type\": \"array\",\n      \"description\": \"Array of 5-7 identified clip segments\",\n      \"minItems\": 5,\n      \"maxItems\": 7,\n      \"items\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"clip_number\": {\n            \"type\": \"integer\",\n            \"description\": \"Sequential clip number (1-7)\"\n          },\n          \"title_hook\": {\n            \"type\": \"string\",\n            \"description\": \"Suggested title hook for the Short (concise, engaging)\"\n          },\n          \"clip_type\": {\n            \"type\": \"string\",\n            \"enum\": [\"Aha! Moment\", \"Validating Statement\", \"Relatable Question\", \"Perspective Shift\"],\n            \"description\": \"Type of clip identified\"\n          },\n          \"timestamp_start\": {\n            \"type\": \"string\",\n            \"pattern\": \"^\\\\d{2}:\\\\d{2}:\\\\d{2},\\\\d{3}$\",\n            \"description\": \"Start timestamp in SRT format (HH:MM:SS,mmm)\"\n          },\n          \"timestamp_end\": {\n            \"type\": \"string\",\n            \"pattern\": \"^\\\\d{2}:\\\\d{2}:\\\\d{2},\\\\d{3}$\",\n            \"description\": \"End timestamp in SRT format (HH:MM:SS,mmm)\"\n          },\n          \"full_text\": {\n            \"type\": \"string\",\n            \"description\": \"Complete word-for-word transcript of the clip\"\n          },\n          \"directors_note\": {\n            \"type\": \"string\",\n            \"description\": \"Brief explanation of why this clip is powerful\"\n          }\n        },\n        \"required\": [\n          \"clip_number\",\n          \"title_hook\",\n          \"clip_type\",\n          \"timestamp_start\",\n          \"timestamp_end\",\n          \"full_text\",\n          \"directors_note\"\n        ]\n      }\n    },\n    \"analysis_summary\": {\n      \"type\": \"string\",\n      \"description\": \"Brief summary of the overall video content\"\n    }\n  },\n  \"required\": [\"clips\"]\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1,
      "position": [
        784,
        1168
      ],
      "id": "1acfe26d-e6cf-407a-9604-106a1924aebe",
      "name": "Stage 1: Output Parser"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ \"**You are:** A specialist Short-Form Video Producer and Content Strategist for mental health and trauma recovery content.\\n\\n**Your Goal:** Analyze this SRT subtitle file and identify the **Top 5-7 most powerful clips** (15-60 seconds each) that can become high-impact YouTube Shorts.\\n\\n**The Channel:** Created by Peggy Oliveira, MSW, for survivors of childhood trauma. Brand tone: Compassionate, Validating, Authoritative, Healing-Focused.\\n\\n**What to Look For:**\\n\\n1. **Aha! Moments:** Clear definitions of psychological terms (emotional flashback, fawning, inner child) or perspective shifts (\\\"You're not broken, you are...\\\")\\n2. **Validating Statements:** Direct empathy (\\\"It was not your fault\\\")\\n3. **Relatable Questions:** Clips starting with powerful hooks (\\\"Do you ever find yourself...?\\\")\\n4. **Perspective Shifts:** Reframing negative beliefs\\n5. **Duration:** 15-60 seconds when spoken\\n6. **Self-Contained:** Must make complete sense on its own\\n\\n**Avoid:**\\n- Academic content without emotional payoff\\n- Dependent on prior context\\n- Listicle format (\\\"The third thing is...\\\")\\n\\n**SRT Content:**\\n\\n\" + $json.data }}",
        "hasOutputParser": true,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        592,
        992
      ],
      "id": "a6ac1234-fab1-4b55-a1e2-cc0300dda843",
      "name": "Stage 1: Clip Identification"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "clips-found",
              "leftValue": "={{ $json.clips.length }}",
              "rightValue": 0,
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        880,
        992
      ],
      "id": "5cf1c35a-e1bc-4a69-abb1-bbeb975f879e",
      "name": "Check If Clips Found"
    },
    {
      "parameters": {
        "jsCode": "// Parse structured JSON output from Stage 1 AI Agent\n// With Structured Output Parser, data comes directly in top-level fields (not wrapped in 'output')\nconst inputData = $input.first().json;\n\n// Check if we have clips directly (from Structured Output Parser)\nif (!inputData.clips) {\n  throw new Error('No clips field in AI Agent response. Available fields: ' + JSON.stringify(Object.keys(inputData)));\n}\n\nconst parsedOutput = inputData; // Data is already structured\n\n// Function to convert SRT timestamp to seconds\nfunction srtToSeconds(timestamp) {\n  const [time, ms] = timestamp.split(',');\n  const [hours, minutes, seconds] = time.split(':').map(Number);\n  return hours * 3600 + minutes * 60 + seconds + (parseInt(ms) / 1000);\n}\n\n// Function to convert seconds to SRT timestamp\nfunction secondsToSRT(seconds) {\n  const hours = Math.floor(seconds / 3600);\n  const minutes = Math.floor((seconds % 3600) / 60);\n  const secs = Math.floor(seconds % 60);\n  const ms = Math.round((seconds % 1) * 1000);\n  return `${String(hours).padStart(2, '0')}:${String(minutes).padStart(2, '0')}:${String(secs).padStart(2, '0')},${String(ms).padStart(3, '0')}`;\n}\n\n// Function to sanitize title for filename\nfunction sanitizeTitle(title) {\n  return title.toLowerCase().replace(/[^a-z0-9]+/g, '_').replace(/^_+|_+$/g, '');\n}\n\n// Extract power words from text (simple heuristic: words in caps, emotional words)\nfunction extractPowerWords(text, title) {\n  const emotionalWords = ['trauma', 'guilt', 'shame', 'healing', 'broken', 'safe', 'worthy', 'valid', 'fault'];\n  const words = text.toLowerCase().split(/\\s+/);\n  const found = words.filter(w => emotionalWords.includes(w)).slice(0, 2);\n  \n  // Add title words if we don't have enough\n  if (found.length < 2) {\n    const titleWords = title.split(/\\s+/).filter(w => w.length > 4).slice(0, 3 - found.length);\n    found.push(...titleWords);\n  }\n  \n  return found.length > 0 ? found : ['healing', 'trauma'];\n}\n\n// Convert from schema format to internal format with synthetic text_styling\nconst clips = parsedOutput.clips.map(clip => {\n  const startSeconds = srtToSeconds(clip.timestamp_start);\n  const endSeconds = srtToSeconds(clip.timestamp_end);\n  const duration = parseFloat((endSeconds - startSeconds).toFixed(3));\n  \n  // Generate synthetic text_styling (will be enhanced by Stage 2 later if needed)\n  const ctaStartSeconds = Math.max(startSeconds, endSeconds - 8); // Last 8 seconds\n  const hookTitle = clip.title_hook.replace(/\\s+/g, '\\n').substring(0, 60); // Break into lines\n  \n  return {\n    index: clip.clip_number,\n    title: clip.title_hook,\n    title_sanitized: sanitizeTitle(clip.title_hook),\n    type: clip.clip_type,\n    type_sanitized: sanitizeTitle(clip.clip_type),\n    start_timestamp: clip.timestamp_start,\n    end_timestamp: clip.timestamp_end,\n    start_seconds: startSeconds,\n    end_seconds: endSeconds,\n    duration: duration,\n    text: clip.full_text,\n    notes: clip.directors_note,\n    text_styling: {\n      hook_title_overlay: hookTitle,\n      power_words: extractPowerWords(clip.full_text, clip.title_hook),\n      cta_start_timestamp: secondsToSRT(ctaStartSeconds),\n      cta_promise_text: 'Watch the full video:',\n      cta_verbal_cue: ''\n    }\n  };\n});\n\nif (clips.length === 0) {\n  throw new Error('No clips found in AI output.');\n}\n\nreturn [{\n  json: {\n    clips: clips,\n    total_clips: clips.length,\n    ai_output: JSON.stringify(parsedOutput),\n    task_id: $('Extract Task ID').item.json.task_id,\n    youtube_url: $('Validate Input').item.json.youtube_url\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1088,
        976
      ],
      "id": "be4a540b-4406-4396-8f65-140dc0623e05",
      "name": "Parse AI Clips"
    },
    {
      "parameters": {
        "fileName": "=/tmp/video_{{ $('Extract Task ID').item.json.task_id }}.mp4",
        "options": {}
      },
      "type": "n8n-nodes-base.writeBinaryFile",
      "typeVersion": 1,
      "position": [
        1168,
        1280
      ],
      "id": "2b7e418c-81fc-48d9-bcba-e172b09e9f19",
      "name": "Write Video to Temp"
    },
    {
      "parameters": {
        "fileName": "=/tmp/video_{{ $('Extract Task ID').item.json.task_id }}.srt",
        "options": {}
      },
      "type": "n8n-nodes-base.writeBinaryFile",
      "typeVersion": 1,
      "position": [
        1024,
        832
      ],
      "id": "3bb9a32f-b3d3-4da3-aaa4-187b27b74a8b",
      "name": "Write SRT to Temp"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "numberInputs": 4,
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        1568,
        944
      ],
      "id": "aacd9d64-2704-4733-b428-e6cb6e3d954e",
      "name": "Merge Temp File Results"
    },
    {
      "parameters": {
        "jsCode": "// Format no-clips-found response\nconst aiOutput = $input.first().json.output;\n\nreturn [{\n  json: {\n    status: 'no_clips_found',\n    clips_found: false,\n    analysis: aiOutput,\n    message: 'No suitable high-impact clips found in this video. The AI analysis explains why.',\n    suggestion: 'Try a different video with more educational/teaching content about trauma recovery concepts.'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1424,
        1280
      ],
      "id": "1a3f6cb3-9ead-40eb-a15a-2e6d234b1555",
      "name": "Format No Clips Response"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        688,
        400
      ],
      "id": "7d2bd611-76b9-4467-b8e3-bd60600695e4",
      "name": "Respond to Webhook1"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "claude-sonnet-4-5-20250929",
          "mode": "list",
          "cachedResultName": "Claude Sonnet 4.5"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        560,
        1168
      ],
      "id": "f800e27a-b8dc-4906-8f0d-7b88ba4ac1b0",
      "name": "Anthropic Chat Model",
      "credentials": {
        "anthropicApi": {
          "id": "9ITdZP15p3HH1JkB",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "fileName": "=/tmp/whisperx_{{ $('Extract Task ID').item.json.task_id }}.json",
        "options": {}
      },
      "type": "n8n-nodes-base.writeBinaryFile",
      "typeVersion": 1,
      "position": [
        1024,
        640
      ],
      "id": "36ae7354-75d2-4b6b-aa43-fa1b86fef2e1",
      "name": "Write WhisperX JSON to Temp"
    },
    {
      "parameters": {
        "jsCode": "const whisperxData = JSON.parse($input.first().json.data);\nconst taskId = $('Extract Task ID').item.json.task_id;\n\n// Convert JSON to binary for file writing\nconst jsonString = JSON.stringify(whisperxData, null, 2);\nconst buffer = Buffer.from(jsonString, 'utf-8');\n\nreturn [{ \n  json: { \n    task_id: taskId \n  },\n  binary: {\n    data: {\n      data: buffer.toString('base64'),\n      mimeType: 'application/json',\n      fileName: `whisperx_${taskId}.json`\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        816,
        640
      ],
      "id": "99fa1c11-1590-4248-beef-21f601d812d5",
      "name": "Parse WhisperX JSON"
    },
    {
      "parameters": {
        "operation": "text",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        560,
        640
      ],
      "id": "d2662e62-b5d9-4284-9084-c9ec14f8e0e1",
      "name": "Extract WhisperX JSON Content"
    },
    {
      "parameters": {
        "url": "=http://yttools:8456/api/download/{{ $json.task_id }}/transcript_json",
        "options": {
          "response": {
            "response": {
              "responseFormat": "file"
            }
          },
          "timeout": 30000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        352,
        640
      ],
      "id": "2fc7e30b-77f3-4da4-b2ce-e8e660ec2596",
      "name": "Download WhisperX JSON"
    },
    {
      "parameters": {
        "url": "=http://yttools:8456/api/download/{{ $json.task_id }}/segment_srt",
        "options": {
          "response": {
            "response": {
              "responseFormat": "file"
            }
          },
          "timeout": 30000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        304,
        832
      ],
      "id": "63d79898-9674-4523-9b42-fb78cf2242da",
      "name": "Download Segment SRT"
    },
    {
      "parameters": {
        "jsCode": "// Extract clips data from merged inputs\n// Input 0: Write Video to Temp\n// Input 1: Write SRT to Temp  \n// Input 2: Parse AI Clips (has the actual data we need)\n// Input 3: Write WhisperX JSON to Temp\n\nconst inputs = $input.all();\n\n// Find the input that has clips data (from Parse AI Clips)\nlet parseClipsData = null;\nfor (const input of inputs) {\n  if (input.json.clips) {\n    parseClipsData = input.json;\n    break;\n  }\n}\n\nif (!parseClipsData || !parseClipsData.clips) {\n  throw new Error('Parse AI Clips data not found in merge inputs');\n}\n\nreturn [{\n  json: {\n    clips: parseClipsData.clips,\n    total_clips: parseClipsData.total_clips,\n    task_id: parseClipsData.task_id,\n    youtube_url: parseClipsData.youtube_url,\n    ai_output: parseClipsData.ai_output\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1776,
        976
      ],
      "id": "5352e0fb-b46b-498b-bfbf-512200f5fee1",
      "name": "Extract Clips Data"
    },
    {
      "parameters": {
        "jsCode": "// Combine clip data with temp file paths\n// After merge, data from all three inputs is combined\nconst inputData = $input.first().json;\n\n// Get clips data (should come from Parse AI Clips input)\nconst clips = inputData.clips;\nconst taskId = inputData.task_id;\nconst youtubeUrl = inputData.youtube_url;\n\nif (!clips) {\n  throw new Error('clips field not found in merged data. Input structure: ' + JSON.stringify(Object.keys(inputData)));\n}\n\nconst videoPath = `/tmp/video_${taskId}.mp4`;\nconst srtPath = `/tmp/video_${taskId}.srt`;\n\nreturn [{\n  json: {\n    clips: clips,\n    total_clips: clips.length,\n    task_id: taskId,\n    youtube_url: youtubeUrl,\n    video_path: videoPath,\n    srt_path: srtPath\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2048,
        576
      ],
      "id": "7394bbad-e530-4970-a083-0aceb4096141",
      "name": "Add Temp Paths to Data"
    },
    {
      "parameters": {
        "jsCode": "// Wait for directory creation, then pass through original data\nconst originalData = $('Add Temp Paths to Data').item.json;\nreturn [{ json: originalData }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2672,
        576
      ],
      "id": "174435cc-1ff5-4b25-b00f-004032b29485",
      "name": "Wait for Directory Creation"
    },
    {
      "parameters": {
        "fieldToSplitOut": "clips",
        "include": "allOtherFields",
        "options": {}
      },
      "type": "n8n-nodes-base.splitOut",
      "typeVersion": 1,
      "position": [
        2048,
        800
      ],
      "id": "67eca8de-2892-485e-9d44-7e6bf6483edc",
      "name": "Split Out Clips"
    },
    {
      "parameters": {
        "command": "mkdir -p /nas/PeggysExtraStorage/videos-to-process/processed/shorts"
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        2256,
        576
      ],
      "id": "02ebee5e-8500-4a62-b75d-e559e29758cf",
      "name": "Create Output Directory"
    },
    {
      "parameters": {
        "command": "mkdir -p /nas/PeggysExtraStorage/videos-to-process/scratch"
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        2464,
        576
      ],
      "id": "9f58a82a-aed5-492a-b133-9ed593bfaf09",
      "name": "Create Scratch Directory"
    },
    {
      "parameters": {
        "jsCode": "// Build ffmpeg command for extracting and enhancing clip\n// Get the original clip data from 'Split Out Clips' node (before Execute Command)\nconst splitOutData = $('Split Out Clips').item.json;\nconst data = splitOutData;\nconst clip = data.clips || data; // Handle both nested and flat structures\nconst videoPath = data.video_path;\nconst taskId = data.task_id;\nconst aiOutput = data.ai_output; // Pass through AI output\n\n// Get video title from YouTube URL or use task ID\nconst youtubeUrl = data.youtube_url || '';\nconst videoId = youtubeUrl.match(/(?:v=|youtu\\.be\\/)([^&\\?]+)/)?.[1] || taskId;\nconst baseFilename = `${videoId}_clip_${String(clip.index).padStart(2, '0')}_${clip.type_sanitized}`;\n\nconst outputPath = `/nas/PeggysExtraStorage/videos-to-process/processed/shorts/${baseFilename}.mp4`;\nconst assPath = `/tmp/subtitle_${taskId}_clip_${String(clip.index).padStart(2, '0')}.ass`;\n\n// Build ffmpeg command with:\n// 1. Extract segment (-ss start, -to end)\n// 2. Crop to 9:16 vertical format\n// 3. Burn-in ASS subtitles with custom styling and text overlays\n// 4. Encode with H.264 + AAC\n// Build ffmpeg command for extracting clip WITHOUT subtitles\n// Subtitles will be added in a later step after WhisperX transcription\nconst outputPathNoSubs = `/nas/PeggysExtraStorage/videos-to-process/scratch/${baseFilename}_nosubs.mp4`;\n\nconst ffmpegCmd = `ffmpeg -y -i \\\"${videoPath}\\\" \\\\\n    -ss ${clip.start_seconds} \\\\\n    -to ${clip.end_seconds} \\\\\n    -vf \\\"crop=ih*9/16:ih\\\" \\\\\n    -c:v libx264 -crf 23 -preset fast \\\\\n    -c:a aac -b:a 128k \\\\\n    -movflags +faststart \\\\\n    \\\"${outputPathNoSubs}\\\"`;\n\nreturn [{\n  json: {\n    ...data,\n    clip: clip,\n    ffmpeg_command: ffmpegCmd,\n    output_path_nosubs: outputPathNoSubs,\n    output_path_final: outputPath,\n    base_filename: baseFilename,\n    ass_path: assPath,\n    ai_output: aiOutput\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2256,
        800
      ],
      "id": "3128c629-8156-4ec3-8ec2-7c7b00a0ffdb",
      "name": "Prepare ffmpeg Command"
    },
    {
      "parameters": {
        "command": "={{ $json.ffmpeg_command }}"
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        2464,
        800
      ],
      "id": "998886ee-e2cc-45de-9935-1ee7f3688c6e",
      "name": "Extract Video Clip"
    },
    {
      "parameters": {
        "filePath": "={{ $('Prepare ffmpeg Command').item.json.output_path_nosubs }}"
      },
      "type": "n8n-nodes-base.readBinaryFile",
      "typeVersion": 1,
      "position": [
        2672,
        800
      ],
      "id": "bd60380d-dad0-478f-b998-155f73f5aec4",
      "name": "Read Clip Video File"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://whisperx:8000/transcribe",
        "sendBody": true,
        "contentType": "multipart-form-data",
        "bodyParameters": {
          "parameters": [
            {
              "parameterType": "formBinaryData",
              "name": "file",
              "inputDataFieldName": "data"
            },
            {
              "name": "model",
              "value": "base"
            },
            {
              "name": "enable_diarization",
              "value": "false"
            }
          ]
        },
        "options": {
          "allowUnauthorizedCerts": true,
          "timeout": 120000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2048,
        1024
      ],
      "id": "d13cea1d-7532-45c8-874f-792e830edcc3",
      "name": "Transcribe Short Video with WhisperX"
    },
    {
      "parameters": {
        "jsCode": "// Extract WhisperX transcription for this entire short video clip\n// Timestamps now start at 0:00:00 for the clip (not original video time)\nconst whisperxResult = $input.first().json;\nconst prepareData = $('Prepare ffmpeg Command').item.json;\n\n// Verify we got segments back\nif (!whisperxResult.segments || whisperxResult.segments.length === 0) {\n  throw new Error(`WhisperX returned no segments for clip ${prepareData.clip.index}`);\n}\n\nconsole.log(`WhisperX transcribed ${whisperxResult.segments.length} segments for clip ${prepareData.clip.index}`);\nconsole.log(`Duration: ${prepareData.clip.duration}s, Language: ${whisperxResult.language}`);\n\n// Pass through clip data + add WhisperX results\nreturn [{\n  json: {\n    ...prepareData,\n    whisperx_segments: whisperxResult.segments,\n    whisperx_srt: whisperxResult.srt,\n    whisperx_segments_srt: whisperxResult.segments_srt,\n    whisperx_txt: whisperxResult.txt,\n    clip_language: whisperxResult.language,\n    num_segments: whisperxResult.segments.length\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2256,
        1024
      ],
      "id": "37e06fb1-22fc-4d27-8b08-17710b1b1a8b",
      "name": "Parse WhisperX Clip Response"
    },
    {
      "parameters": {
        "jsCode": "// Generate sentence-aware ASS subtitles directly from WhisperX segments\nconst data = $input.first().json;\nconst clip = data.clip;\nconst taskId = data.task_id;\nconst segments = data.whisperx_segments;\n\n// ===== CONFIGURATION =====\nconst CONFIG = {\n  wordsToShow: 3,\n  fontName: 'Arial',\n  fontSize: 80,  // Reduced from 130\n  fontColor: 'FFFFFF',\n  outlineColor: '000000',\n  backgroundColor: '000000',\n  highlightFontSize: 100,  // Reduced from 150 (still 25% larger than base for zoom effect)\n  highlightColor: '00FFFF',\n  bold: 0,\n  italic: 0,\n  underline: 0,\n  strikeout: 0,\n  scaleX: 100,\n  scaleY: 100,\n  spacing: 0,\n  angle: 0,\n  borderStyle: 1,\n  outline: 8,  // Reduced from 10\n  shadow: 1,\n  alignment: 2,\n  marginL: 10,\n  marginR: 10,\n  marginV: 300,\n  videoWidth: 1080,  // 9:16 vertical format\n  videoHeight: 1920,\n  maxGapTimeMs: 2000,\n  // Hook title styling\n  hookTitleFontSize: 120,  // Reduced from 180\n  hookTitleColor: 'FFFF00',  // Yellow\n  hookTitleDuration: 2.0,  // Show for 2 seconds at start\n  hookTitleAlignment: 5,  // Center\n  hookTitleMarginV: 100,\n  // CTA styling\n  ctaFontSize: 90,  // Reduced from 140\n  ctaColor: 'FF00FF',  // Magenta\n  ctaDuration: 8.0,  // Show for last 8 seconds\n  ctaAlignment: 8,  // Top center\n  ctaMarginV: 100\n};\n\n// Helper: convert seconds to ASS time format (H:MM:SS.cs)\nfunction formatTime(sec) {\n  const h = Math.floor(sec / 3600);\n  const m = Math.floor((sec % 3600) / 60);\n  const s = Math.floor(sec % 60);\n  const cs = Math.floor((sec - Math.floor(sec)) * 100);\n  return `${h}:${m.toString().padStart(2, '0')}:${s.toString().padStart(2, '0')}.${cs.toString().padStart(2, '0')}`;\n}\n\n// Creates subtitle text with specified word highlighted\nfunction createSubtitleText(wordGroup, highlightIndex) {\n  let line = '';\n  wordGroup.forEach((word, i) => {\n    if (i > 0) line += ' ';\n    if (i === highlightIndex) {\n      line += `{\\\\fs${CONFIG.highlightFontSize}\\\\c&H${CONFIG.highlightColor}&}${word.word.trim()}{\\\\r}`;\n    } else {\n      line += word.word.trim();\n    }\n  });\n  return line;\n}\n\n// Process all segments to get all words\nlet allWords = [];\nsegments.forEach(segment => {\n  if (segment.words && segment.words.length > 0) {\n    allWords = allWords.concat(segment.words);\n  }\n});\n\n// Sort by start time\nallWords.sort((a, b) => a.start - b.start);\n\n// Create sentence-aware word groups\nfunction createSentenceAwareGroups(words) {\n  const groups = [];\n  let currentGroup = [];\n  \n  for (let i = 0; i < words.length; i++) {\n    const currentWord = words[i];\n    currentGroup.push(currentWord);\n    \n    const endsWithPeriod = currentWord.word.trim().endsWith('.');\n    \n    if (currentGroup.length >= CONFIG.wordsToShow || endsWithPeriod || i === words.length - 1) {\n      if (currentGroup.length > 0) {\n        groups.push([...currentGroup]);\n        currentGroup = [];\n      }\n    }\n  }\n  \n  if (currentGroup.length > 0) {\n    groups.push(currentGroup);\n  }\n  \n  return groups;\n}\n\nconst wordGroups = createSentenceAwareGroups(allWords);\nlet dialogueLines = [];\n\n// Generate dialogue lines for each word\nfor (let i = 0; i < allWords.length; i++) {\n  const currentWord = allWords[i];\n  \n  // Find which group contains this word\n  let groupIndex = -1;\n  let positionIndex = -1;\n  \n  for (let g = 0; g < wordGroups.length; g++) {\n    const wordIndex = wordGroups[g].findIndex(w => \n      w.start === currentWord.start && w.end === currentWord.end && w.word === currentWord.word);\n    \n    if (wordIndex !== -1) {\n      groupIndex = g;\n      positionIndex = wordIndex;\n      break;\n    }\n  }\n  \n  if (groupIndex === -1) continue;\n  \n  const wordGroup = wordGroups[groupIndex];\n  const startTime = currentWord.start;\n  const endTime = currentWord.end;\n  const formattedStart = formatTime(startTime);\n  const formattedEnd = formatTime(endTime);\n  const subtitleText = createSubtitleText(wordGroup, positionIndex);\n  \n  dialogueLines.push({\n    start: startTime,\n    end: endTime,\n    formattedStart,\n    formattedEnd,\n    text: subtitleText,\n    group: groupIndex,\n    position: positionIndex\n  });\n}\n\n// Fill gaps between dialogues in same group\nfor (let i = 0; i < dialogueLines.length - 1; i++) {\n  const current = dialogueLines[i];\n  const next = dialogueLines[i + 1];\n  \n  if (current.group === next.group && next.start - current.end > 0 && next.start - current.end <= CONFIG.maxGapTimeMs / 1000) {\n    current.end = next.start;\n    current.formattedEnd = formatTime(current.end);\n  }\n}\n\n// Build ASS file content with multiple styles\nlet ass = `[Script Info]\nTitle: Sentence-Aware Fixed Position Subtitles with Hook and CTA\nScriptType: v4.00+\nPlayResX: ${CONFIG.videoWidth}\nPlayResY: ${CONFIG.videoHeight}\n\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\nStyle: Default,${CONFIG.fontName},${CONFIG.fontSize},&H${CONFIG.fontColor},&H${CONFIG.outlineColor},&H${CONFIG.outlineColor},&H${CONFIG.backgroundColor},${CONFIG.bold},${CONFIG.italic},${CONFIG.underline},${CONFIG.strikeout},${CONFIG.scaleX},${CONFIG.scaleY},${CONFIG.spacing},${CONFIG.angle},${CONFIG.borderStyle},${CONFIG.outline},${CONFIG.shadow},${CONFIG.alignment},${CONFIG.marginL},${CONFIG.marginR},${CONFIG.marginV},1\nStyle: HookTitle,${CONFIG.fontName},${CONFIG.hookTitleFontSize},&H${CONFIG.hookTitleColor},&H${CONFIG.outlineColor},&H${CONFIG.outlineColor},&H${CONFIG.backgroundColor},1,${CONFIG.italic},${CONFIG.underline},${CONFIG.strikeout},${CONFIG.scaleX},${CONFIG.scaleY},${CONFIG.spacing},${CONFIG.angle},${CONFIG.borderStyle},${CONFIG.outline},${CONFIG.shadow},${CONFIG.hookTitleAlignment},${CONFIG.marginL},${CONFIG.marginR},${CONFIG.hookTitleMarginV},1\nStyle: CTA,${CONFIG.fontName},${CONFIG.ctaFontSize},&H${CONFIG.ctaColor},&H${CONFIG.outlineColor},&H${CONFIG.outlineColor},&H${CONFIG.backgroundColor},1,${CONFIG.italic},${CONFIG.underline},${CONFIG.strikeout},${CONFIG.scaleX},${CONFIG.scaleY},${CONFIG.spacing},${CONFIG.angle},${CONFIG.borderStyle},${CONFIG.outline},${CONFIG.shadow},${CONFIG.ctaAlignment},${CONFIG.marginL},${CONFIG.marginR},${CONFIG.ctaMarginV},1\n\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n`;\n\n// Add hook title at the beginning\nconst hookTitle = clip.text_styling?.hook_title_overlay || clip.title;\nconst hookEndTime = Math.min(CONFIG.hookTitleDuration, clip.duration);\nass += `Dialogue: 1,${formatTime(0)},${formatTime(hookEndTime)},HookTitle,,0,0,0,,${hookTitle.replace(/\\n/g, '\\\\N')}\\n`;\n\n// Add all word-by-word dialogue lines\ndialogueLines.forEach(line => {\n  ass += `Dialogue: 0,${line.formattedStart},${line.formattedEnd},Default,,0,0,0,,${line.text}\\n`;\n});\n\n// Add CTA at the end\nconst ctaText = clip.text_styling?.cta_promise_text || 'Watch the full video';\nconst ctaStartTime = Math.max(0, clip.duration - CONFIG.ctaDuration);\nass += `Dialogue: 2,${formatTime(ctaStartTime)},${formatTime(clip.duration)},CTA,,0,0,0,,${ctaText}\\n`;\n\nconst assPath = `/nas/PeggysExtraStorage/videos-to-process/scratch/subtitle_clip_${taskId}_${String(clip.index).padStart(2, '0')}.ass`;\n\nreturn [{\n  json: {\n    ...data,\n    ass_path: assPath,\n    subtitle_generated: true,\n    total_words: allWords.length,\n    total_groups: wordGroups.length,\n    total_dialogue_lines: dialogueLines.length\n  },\n  binary: {\n    data: {\n      data: Buffer.from(ass).toString('base64'),\n      mimeType: 'text/x-ssa',\n      fileName: `subtitle_clip_${taskId}_${String(clip.index).padStart(2, '0')}.ass`\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2464,
        1024
      ],
      "id": "6fe70632-03c9-4c9a-bb95-bfeb947ff376",
      "name": "Generate Sentence-Aware ASS Subtitles"
    },
    {
      "parameters": {
        "fileName": "={{ $json.ass_path }}",
        "options": {}
      },
      "type": "n8n-nodes-base.writeBinaryFile",
      "typeVersion": 1,
      "position": [
        2672,
        1024
      ],
      "id": "df8d85ab-274b-473e-ace2-580444640dc8",
      "name": "Write ASS File to Scratch"
    },
    {
      "parameters": {
        "jsCode": "// Apply ASS subtitles to the no-subs video\nconst data = $input.first().json;\n\nconst finalCmd = `ffmpeg -y -i \"${data.output_path_nosubs}\" \\\\\n    -vf \"ass='${data.ass_path}'\" \\\\\n    -c:v libx264 -crf 23 -preset fast \\\\\n    -c:a copy \\\\\n    -movflags +faststart \\\\\n    \"${data.output_path_final}\"`;\n\nreturn [{\n  json: {\n    ...data,\n    final_ffmpeg_command: finalCmd\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2048,
        1264
      ],
      "id": "a30e6c93-42a6-4f4f-9b2b-21b7a785a17a",
      "name": "Build Final ffmpeg Command"
    },
    {
      "parameters": {
        "command": "={{ $json.final_ffmpeg_command }}"
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        2256,
        1264
      ],
      "id": "fa3600a1-4669-4dbe-8eae-c8d0e1f92e1f",
      "name": "Apply Subtitles to Video"
    },
    {
      "parameters": {
        "jsCode": "// Verify clip was created by checking ffmpeg exit code\nconst execResult = $input.first().json;\nconst exitCode = execResult.exitCode;\n\n// Get clip data from Build Final ffmpeg Command node\nconst buildData = $('Build Final ffmpeg Command').item.json;\nconst clip = buildData.clip;\n\n// ffmpeg returns 0 on success\nif (exitCode === 0) {\n  return [{\n    json: {\n      clip_index: clip.index,\n      clip_title: clip.title,\n      output_path_nosubs: buildData.output_path_nosubs,\n      output_path_final: buildData.output_path_final,\n      duration: clip.duration,\n      status: 'success',\n      ai_output: buildData.ai_output\n    }\n  }];\n} else {\n  return [{\n    json: {\n      clip_index: clip.index,\n      clip_title: clip.title,\n      status: 'failed',\n      error: `ffmpeg failed with exit code ${exitCode}`,\n      stderr: execResult.stderr || 'No error output',\n      ai_output: buildData.ai_output\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2464,
        1264
      ],
      "id": "57234242-7d9b-4f6f-b306-bec1f6f75ace",
      "name": "Verify Clip Created"
    },
    {
      "parameters": {
        "jsCode": "// Aggregate all clip results\nconst allClips = $input.all();\nconst successful = allClips.filter(c => c.json.status === 'success');\nconst failed = allClips.filter(c => c.json.status === 'failed');\n\n// Get ai_output from first item (all items have the same ai_output)\nconst aiOutput = allClips[0]?.json.ai_output;\n\nreturn [{\n  json: {\n    total_clips: allClips.length,\n    successful_clips: successful.length,\n    failed_clips: failed.length,\n    clips: successful.map(c => ({\n      index: c.json.clip_index,\n      title: c.json.clip_title,\n      path_nosubs: c.json.output_path_nosubs,\n      path_final: c.json.output_path_final,\n      duration: c.json.duration\n    })),\n    errors: failed.map(c => ({\n      index: c.json.clip_index,\n      title: c.json.clip_title,\n      error: c.json.error\n    })),\n    ai_output: aiOutput\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2672,
        1264
      ],
      "id": "79d73745-ef55-49e4-9bbb-96a8fd89d7bd",
      "name": "Aggregate Clip Results"
    },
    {
      "parameters": {
        "jsCode": "// Format successful clips response with extraction results\nconst clipResults = $input.first().json;\nconst aiOutput = clipResults.ai_output;\n\nreturn [{\n  json: {\n    status: 'success',\n    clips_found: true,\n    clips_extracted: clipResults.successful_clips,\n    total_clips_attempted: clipResults.total_clips,\n    analysis: aiOutput,\n    extracted_shorts: clipResults.clips,\n    storage_path_final: '/nas/PeggysExtraStorage/videos-to-process/processed/shorts',\n    storage_path_nosubs: '/nas/PeggysExtraStorage/videos-to-process/scratch',\n    message: `Successfully extracted ${clipResults.successful_clips} short video clips with sentence-aware subtitles (both versions saved)`,\n    errors: clipResults.errors\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2048,
        1472
      ],
      "id": "cc9c79f6-f37f-4bd6-9ce3-90a35402364e",
      "name": "Format Success Response"
    }
  ],
  "connections": {
    "YouTube Download Webhook": {
      "main": [
        [
          {
            "node": "Validate Input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Input": {
      "main": [
        [
          {
            "node": "Submit to yttools",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Submit to yttools": {
      "main": [
        [
          {
            "node": "Extract Task ID",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Task ID": {
      "main": [
        [
          {
            "node": "Format Immediate Response",
            "type": "main",
            "index": 0
          },
          {
            "node": "Wait 3s",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Immediate Response": {
      "main": [
        [
          {
            "node": "Respond to Webhook1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Progress: Extracting Clips": {
      "main": [
        [
          {
            "node": "Merge Temp File Results",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Progress: Adding Subtitles": {
      "main": [
        [
          {
            "node": "Format Success Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait 3s": {
      "main": [
        [
          {
            "node": "Check Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Status": {
      "main": [
        [
          {
            "node": "Check Completion",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Completion": {
      "main": [
        [
          {
            "node": "Is Complete?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is Complete?": {
      "main": [
        [
          {
            "node": "Download Audio",
            "type": "main",
            "index": 0
          },
          {
            "node": "Download Video",
            "type": "main",
            "index": 0
          },
          {
            "node": "Download Segment SRT",
            "type": "main",
            "index": 0
          },
          {
            "node": "Download WhisperX JSON",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Wait 3s",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download Video": {
      "main": [
        [
          {
            "node": "Write Video to Temp",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract SRT Content": {
      "main": [
        [
          {
            "node": "Stage 1: Clip Identification",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Stage 1: Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Stage 1: Clip Identification",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Stage 1: Clip Identification": {
      "main": [
        [
          {
            "node": "Check If Clips Found",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check If Clips Found": {
      "main": [
        [
          {
            "node": "Parse AI Clips",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Format No Clips Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse AI Clips": {
      "main": [
        [
          {
            "node": "Progress: Extracting Clips",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Write Video to Temp": {
      "main": [
        [
          {
            "node": "Merge Temp File Results",
            "type": "main",
            "index": 3
          }
        ]
      ]
    },
    "Write SRT to Temp": {
      "main": [
        [
          {
            "node": "Merge Temp File Results",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge Temp File Results": {
      "main": [
        [
          {
            "node": "Extract Clips Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Stage 1: Clip Identification",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Write WhisperX JSON to Temp": {
      "main": [
        [
          {
            "node": "Merge Temp File Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse WhisperX JSON": {
      "main": [
        [
          {
            "node": "Write WhisperX JSON to Temp",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract WhisperX JSON Content": {
      "main": [
        [
          {
            "node": "Parse WhisperX JSON",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download WhisperX JSON": {
      "main": [
        [
          {
            "node": "Extract WhisperX JSON Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download Segment SRT": {
      "main": [
        [
          {
            "node": "Extract SRT Content",
            "type": "main",
            "index": 0
          },
          {
            "node": "Write SRT to Temp",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Clips Data": {
      "main": [
        [
          {
            "node": "Add Temp Paths to Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Add Temp Paths to Data": {
      "main": [
        [
          {
            "node": "Create Output Directory",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait for Directory Creation": {
      "main": [
        [
          {
            "node": "Split Out Clips",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Out Clips": {
      "main": [
        [
          {
            "node": "Prepare ffmpeg Command",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Output Directory": {
      "main": [
        [
          {
            "node": "Create Scratch Directory",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Scratch Directory": {
      "main": [
        [
          {
            "node": "Wait for Directory Creation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare ffmpeg Command": {
      "main": [
        [
          {
            "node": "Extract Video Clip",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Video Clip": {
      "main": [
        [
          {
            "node": "Read Clip Video File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Read Clip Video File": {
      "main": [
        [
          {
            "node": "Transcribe Short Video with WhisperX",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Transcribe Short Video with WhisperX": {
      "main": [
        [
          {
            "node": "Parse WhisperX Clip Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse WhisperX Clip Response": {
      "main": [
        [
          {
            "node": "Generate Sentence-Aware ASS Subtitles",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Sentence-Aware ASS Subtitles": {
      "main": [
        [
          {
            "node": "Write ASS File to Scratch",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Write ASS File to Scratch": {
      "main": [
        [
          {
            "node": "Build Final ffmpeg Command",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Final ffmpeg Command": {
      "main": [
        [
          {
            "node": "Apply Subtitles to Video",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Apply Subtitles to Video": {
      "main": [
        [
          {
            "node": "Verify Clip Created",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Verify Clip Created": {
      "main": [
        [
          {
            "node": "Aggregate Clip Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate Clip Results": {
      "main": [
        [
          {
            "node": "Progress: Adding Subtitles",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Success Response": {
      "main": [
        [
          {
            "node": "Progress: Completed",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "meta": {
    "instanceId": "99ff97a0c56026a2c1b3a849547491eb857e68a0b770f2b7c6688eea83f57eda"
  }
}